{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb5a7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# Basic imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# ==========================\n",
    "# Load API Keys\n",
    "# ==========================\n",
    "load_dotenv(\"api.env\")\n",
    "\n",
    "langsmith_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "if not langsmith_key:\n",
    "    raise ValueError(\"LANGSMITH_API_KEY not found in environment or api.env!\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment or api.env!\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2586981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# Initialize LLM & embeddings\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Connect to existing Chroma DB (populated separately)\n",
    "persist_directory = r\"C:\\Users\\ishan\\Automation\\SIH25\\RAG\\chroma_db\"\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"college_pdfsn\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# Retriever for RAG\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2435dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# SQLite DB file\n",
    "DB_FILE = Path(\"conversation_memory.db\")\n",
    "\n",
    "# Initialize SQLite connection\n",
    "conn = sqlite3.connect(DB_FILE, check_same_thread=False)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop old table if exists and create a new one with thread_id\n",
    "cursor.execute(\"DROP TABLE IF EXISTS conversation_history\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE conversation_history (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_id TEXT NOT NULL,\n",
    "    thread_id TEXT NOT NULL,\n",
    "    role TEXT NOT NULL,  -- 'user' or 'assistant'\n",
    "    text TEXT NOT NULL,\n",
    "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1adbf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_history(user_id, thread_id, last_n=5):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT role, text FROM conversation_history\n",
    "        WHERE user_id = ? AND thread_id = ?\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT ?\n",
    "    \"\"\", (user_id, thread_id, last_n))\n",
    "    rows = cursor.fetchall()\n",
    "    # Reverse to chronological order\n",
    "    return [{\"role\": r[0], \"text\": r[1]} for r in reversed(rows)]\n",
    "\n",
    "def save_turn(user_id, thread_id, role, text):\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO conversation_history (user_id, thread_id, role, text)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (user_id, thread_id, role, text))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5460092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "def rag_query(query: str, retriever=retriever):\n",
    "    \"\"\"\n",
    "    Takes a user query and returns:\n",
    "    - retrieved document chunks\n",
    "    - metadata\n",
    "    \"\"\"\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    output = {\n",
    "        \"query\": query,\n",
    "        \"context\": [doc.page_content for doc in retrieved_docs],\n",
    "        \"metadata\": [doc.metadata for doc in retrieved_docs]\n",
    "    }\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2740a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rg_generate(user_id, thread_id, rag_output, language=\"en\", history_turns=5):\n",
    "    # Retrieve conversation history for this thread\n",
    "    history = get_conversation_history(user_id, thread_id, last_n=history_turns)\n",
    "    history_text = \"\"\n",
    "    for turn in history:\n",
    "        history_text += f\"{turn['role'].capitalize()}: {turn['text']}\\n\"\n",
    "\n",
    "    # Context from RAG\n",
    "    context = \"\\n\".join(rag_output[\"context\"])\n",
    "    question = rag_output[\"query\"]\n",
    "\n",
    "    # Construct prompt\n",
    "    final_prompt = f\"\"\"\n",
    "You are an academic assistant. Answer the question using the previous conversation history and  given context as much as possible try to use the context as your main source of knowledge and try to relate as much information from the context as possible if the user asks anything which is completely not there in the context not even a little then use your own brain and when you do in the end just mention \"(not from context)\"\n",
    ". And if the user in not talking about academics you can talk normally. Answer clearly and concisely.\n",
    "\n",
    "Conversation History:\n",
    "{history_text}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in {language}:\n",
    "\"\"\"\n",
    "\n",
    "    from langchain.schema import HumanMessage\n",
    "    response = llm.invoke([HumanMessage(content=final_prompt)])\n",
    "    response_text = response.content\n",
    "\n",
    "    # Save current turn\n",
    "    save_turn(user_id, thread_id, \"user\", question)\n",
    "    save_turn(user_id, thread_id, \"assistant\", response_text)\n",
    "\n",
    "    sources = [meta.get(\"source\", \"N/A\") for meta in rag_output[\"metadata\"]]\n",
    "    return response_text, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8afdfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " Your name is Ishan.\n"
     ]
    }
   ],
   "source": [
    "user_id = \"user_123\"\n",
    "thread_id = \"thread_1\"  # each separate chat can have a unique thread ID\n",
    "user_query = \"Whats my name\"\n",
    "\n",
    "rag_output = rag_query(user_query, retriever)\n",
    "answer, sources = rg_generate(user_id, thread_id, rag_output, language=\"en\")\n",
    "\n",
    "print(\"Answer:\\n\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
